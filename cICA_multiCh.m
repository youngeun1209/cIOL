function [y, w] = cICA_multiCh(X, ref, threshold, w0, learningRate, mu0, lambda0, gamma, maxIter, OverValue)
% Constrained ICA for extracting multi source signals using the reference signals.
%
% Command:
%   [y, w] = cICA_multiCh(X, ref, threshold, w0, learningRate, mu0, lambda0, gamma, maxIter, OverValue)ï¼›
%
% Parameters:
%            y --- extracted source signal, according to the given optimal time delay.
%            w --- corresponding weight vector, that is, y=w'*X.
%            X --- prewhitened observed mixed signals. Each row is a mixed signal.     
%          ref --- reference signal, which can be generated by function genRectangleRef
%                  and genPulseRef
%    threshold --- the closeness of the desired signal and the reference signal is less than 
%                  or equal to the threshold, i.e., closeness(y,ref) - threshold <= 0
%           w0 --- the initial weight vector
% learningRate --- learning rate of the weight w
%          mu0 --- the Lagrange multiplier for constraint g(w)
%      lambda0 --- the Lagrange multiplier for constraint h(w)
%        gamma --- the scalar penalty parameter // learning rate of lagrange multipliers
%  OverValue --- stopping criterion, say, 0.0001. When the changed value 
%                of weighted vector is less than it, then the algorithm stops
%    maxIter --- maximum iterations for estimating each independent component
%


X = real(X);

% fprintf('Starting cICA for extracting the desired source signal ..\n');
[ICnum, IClen]=size(X);
[rR, lR] = size(ref);
w = repmat(w0,1,rR);
oldw = w;

mu = repmat(mu0,rR,1);
lambda = repmat(lambda0,rR,1);
thr = threshold;

flag = 1;
loop = 1;

% compute the autocorrelation matrix Rxx
Rxx = X(:,[1:end]) * X(:,[1:end])' / IClen;

while (flag == 1)
    
    % output at current iteration
    y = w' * X;       
    
    std_y = std(y');                          % standard deviation
    for i=1:rR
        v_Gaus(i,:) = normrnd(0, std_y(i), 1, IClen);    % Gaussian signal with the same mean and variance
    end
    
    rou = mean( log(cosh(y)),2) - mean(log(cosh(v_Gaus)),2); % square root of negentropy loss
    
    % L1: related to the first order deviation of the Lagarange function
    L1 = rou .* ( tanh(y) * X')/IClen ... % negentropy deviation
        + (mu + gamma.* ( mean((y-ref).^2,2) - thr) ).* ( (y - ref) * X')/IClen ... % inequality constraint function deviation
        + (lambda + gamma .* ( mean(y.^2,2) - 1) ) .* ( y  * X')/IClen; % equality constraint function deviation
    
    
    % L2: related to the second order deviation of the Lagarange function
    L2 = mean(( tanh(y).^2 ),2) + rou .* (mean( 1./cosh(y).^2 ,2)) ... % negentropy deviation
        + mu + gamma.* ( mean(y - ref,2).^2 + mean((y-ref).^2,2) - thr )  ... % inequality constraint function deviation
        + lambda + gamma.* ( mean(y,2).^2 + mean(y.^2,2) - 1 ) ;   % equality constraint function deviation
    
    % update of the weight vector
    w = w - learningRate * Rxx * (L1 ./ L2)' ;  % (L1 /L2)'
    w = w/norm(w);
    
    % update of the parameter mu
    thr = threshold * (1-exp(-loop));
    g = mean( (y-ref).^2, 2 ) - thr;    % corresponds to the inequality constraint
    mu = max(0, mu + gamma * g);

    % update of the parameter lambda
    h = mean(y.^2,2) - 1;                    % corresponds to the equality constraint
    lambda = lambda + gamma * h;


    % decide whether the algorithm has converged or not
    wchange = 1-abs(corr2(w,oldw));

    if wchange < OverValue
        flag = 0;
    end

    if loop >= maxIter
        fprintf('After %d iteration, still cannot convergent.\n',loop);
        flag = 0;
    end

    oldw = w;
    loop = loop + 1;

end

% output
y = w'* X;

